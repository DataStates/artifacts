#!/usr/bin/bash
#PBS -l select=9:ngpus=4:ncpus=6
#PBS -l place=scatter
#PBS -l filesystems=grand
#PBS -l walltime=00:10:00
#PBS -A VeloC
#PBS -q debug-scaling

EXP_DIR=$HOME/experiments
INIT_SCRIPT=$EXP_DIR/init-dh-environment2.sh

cd $EXP_DIR
source $INIT_SCRIPT

NUM_CLIENT_NODES=8
SERVER_PROCS=1
SERVER_CMD="${EXP_DIR}/servers/redis.py"
RESULT_DIR="/lus/grand/projects/VeloC/datastates/attn_64gpu_redis_noretire_2/"
STORE_DIR="/lus/grand/projects/VeloC/datastates/models_attn_64gpu_redis_noretire_2/"

METHOD="redis"

mkdir $RESULT_DIR
mkdir $STORE_DIR

/opt/cray/pe/pals/1.1.7/bin/aprun -n $((NUM_CLIENT_NODES*5)) -N 5 python transfer_learn-mpi.py \
	--rand_seed 4 \
	--bulk_storage_path $STORE_DIR \
	--save_result_dir $RESULT_DIR \
	--transfer_method $METHOD \
	--load_data_mode mpicomm \
	--num_gpus_per_task 1 \
	--sample_size 5 \
	--population_size 50  \
	--search_attempts 1000 \
	--num_epochs 1 \
	--beta 1 \
	--application attn \
	--store_weights \
	--test_data_path "/lus/grand/projects/VeloC/mmadhya1/training_attn.h5" \
	--train_data_path "/lus/grand/projects/VeloC/mmadhya1/training_attn.h5" \
	: -n $SERVER_PROCS -N 1 ${SERVER_CMD}
