# DataStates Artifacts
This repository hosts the software artifacts developed to ensure reproducibility of the novel designs proposed through the DataStates project.

Artifacts are organized by publication and can be found in the following subfolders:

1. [Network Architecture Search](./nas/): Robert Underwood, Meghana Madhyastha, Randal Burns, and Bogdan Nicolae. 2024. EvoStore: Towards Scalable Storage of Evolving Learning Models. In Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing (HPDC '24). Association for Computing Machinery. Pisa, Italy. https://doi.org/10.1145/3625549.3658679.

2. [Deep Optimizer States](./deep-optimizer-states/): Avinash Maurya, Jie Ye, M. Mustafa Rafique, Franck Cappello, and Bogdan Nicolae. 2024. Deep Optimizer States: Towards Scalable Training of Transformer Models using Interleaved Offloading. In Proceedings of the 25th International Middleware Conference (Middleware '24). Association for Computing Machinery. Hong Kong. https://doi.org/10.1145/3652892.3700781

3. [MLP-Offload](./MLP-Offload/): Avinash Maurya, M. Mustafa Rafique, Franck Cappello, and Bogdan Nicolae. 2025. MLP-Offload: Multi-Level, Multi-Path Offloading for LLM Pre-training to Break the GPU Memory Wall. In Proceedings of the International Conference for High-Performance Computing, Networking, Storage, and Analysis (SC '25). Association for Computing Machinery. St. Lous, MO. https://doi.org/10.1145/3712285.3759864.
